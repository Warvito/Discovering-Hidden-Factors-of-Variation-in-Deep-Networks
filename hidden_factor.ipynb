{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on https://github.com/Lasagne/Lasagne/blob/highway_example/examples/Hidden%20factors.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.layers import xavier_initializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible results\n",
    "tf.set_random_seed(1)\n",
    "np.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784 # MNIST data input (img shape: 28*28)\n",
    "output_dim = 10 # MNIST total classes (0-9 digits)\n",
    "latent_dim = 2\n",
    "num_hidden_units=500\n",
    "\n",
    "noise_factor = 0.1\n",
    "\n",
    "# variables\n",
    "X = tf.placeholder(tf.float32, shape=[None, input_dim])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, output_dim])\n",
    "\n",
    "# encoder\n",
    "with tf.variable_scope(\"encoder\"):\n",
    "    enc_W1 = tf.get_variable(\"W1\", shape=[input_dim, num_hidden_units], initializer=xavier_initializer())\n",
    "    enc_b1 = tf.get_variable(\"b1\", shape=[num_hidden_units], initializer=tf.zeros_initializer())\n",
    "\n",
    "    enc_W2 = tf.get_variable(\"W2\", shape=[num_hidden_units, num_hidden_units], initializer=xavier_initializer())\n",
    "    enc_b2 = tf.get_variable(\"b2\", shape=[num_hidden_units], initializer=tf.zeros_initializer())\n",
    "\n",
    "# learned representation\n",
    "with tf.variable_scope(\"representation\"):\n",
    "    obs_W = tf.get_variable(\"W_obs\", shape=[num_hidden_units, output_dim], initializer=xavier_initializer())\n",
    "    obs_b = tf.get_variable(\"b_obs\", shape=[output_dim], initializer=tf.zeros_initializer())\n",
    "\n",
    "    lat_W = tf.get_variable(\"W_lat\", shape=[num_hidden_units, latent_dim], initializer=xavier_initializer())\n",
    "    lat_b = tf.get_variable(\"b_lat\", shape=[latent_dim], initializer=tf.zeros_initializer())\n",
    "\n",
    "# decoder\n",
    "with tf.variable_scope(\"decoder\"):\n",
    "    dec_W1 = tf.get_variable(\"W1\", shape=[latent_dim+output_dim, num_hidden_units], initializer=xavier_initializer())\n",
    "    dec_b1 = tf.get_variable(\"b1\", shape=[num_hidden_units], initializer=tf.zeros_initializer())\n",
    "\n",
    "    dec_W2 = tf.get_variable(\"W2\", shape=[num_hidden_units, num_hidden_units], initializer=xavier_initializer())\n",
    "    dec_b2 = tf.get_variable(\"b2\", shape=[num_hidden_units], initializer=tf.zeros_initializer())\n",
    "\n",
    "# output\n",
    "with tf.variable_scope(\"output\"):\n",
    "    out_W = tf.get_variable(\"W\", shape=[num_hidden_units, input_dim], initializer=xavier_initializer())\n",
    "    out_b = tf.get_variable(\"b\", shape=[input_dim], initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "# training model\n",
    "# encoder\n",
    "l_encoder1 = tf.nn.selu(tf.matmul((X + tf.random_normal(shape=tf.shape(X), mean=0., stddev=noise_factor)),\n",
    "                            enc_W1) + enc_b1) # layer with noise\n",
    "l_encoder2 = tf.nn.selu(tf.matmul(l_encoder1, enc_W2) + enc_b2)\n",
    "\n",
    "# learned representation\n",
    "l_observed = tf.matmul(l_encoder2, obs_W) + obs_b \n",
    "l_latent = tf.matmul(l_encoder2, lat_W) + lat_b # linear\n",
    "\n",
    "l_representation = tf.concat([l_latent, y_], 1)\n",
    "\n",
    "# decoder\n",
    "l_decoder1 = tf.nn.selu(tf.matmul(l_representation, dec_W1) + dec_b1)\n",
    "l_decoder2 = tf.nn.selu(tf.matmul(l_decoder1, dec_W2) + dec_b2)\n",
    "\n",
    "# reconstruction layer\n",
    "l_decoder_out = tf.matmul(l_decoder2, out_W) + out_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost\n",
    "alpha=1.0\n",
    "beta=10.0\n",
    "gamma=10.0\n",
    "\n",
    "# unsupervised cost: mean squared error\n",
    "U = tf.reduce_mean(tf.square(l_decoder_out - X))\n",
    "\n",
    "# supervised cost: categorical cross-entropy\n",
    "S = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=l_observed))\n",
    "\n",
    "# XCov cost: cross-covariance\n",
    "y_pred_mean = tf.reduce_mean(l_observed, axis=0)\n",
    "z_mean = tf.reduce_mean(l_latent, axis=0)\n",
    "y_pred_centered = l_observed - y_pred_mean # (n, i)\n",
    "z_centered = l_latent - z_mean # (n, j)\n",
    "\n",
    "outer_prod =  tf.expand_dims(y_pred_centered, 2) * tf.expand_dims(z_centered, 1)  # (n, i, j)\n",
    "C = 0.5 * tf.reduce_sum(tf.square(tf.reduce_mean(outer_prod, axis=0)))\n",
    "\n",
    "cost = alpha * U + beta * S + gamma * C\n",
    "reg = tf.nn.l2_loss(enc_W1) \\\n",
    "      + tf.nn.l2_loss(enc_W2) \\\n",
    "      + tf.nn.l2_loss(obs_W) \\\n",
    "      + tf.nn.l2_loss(lat_W) \\\n",
    "      + tf.nn.l2_loss(dec_W1) \\\n",
    "      + tf.nn.l2_loss(dec_W2) \\\n",
    "      + tf.nn.l2_loss(out_W)\n",
    "\n",
    "l2_reg = 0.01\n",
    "cost += l2_reg * reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "display_step = 10\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, c = sess.run([train_op, cost], feed_dict={X: batch_x,\n",
    "                                                        y_: batch_y})\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "print(\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "# encoder\n",
    "l_encoder1_test = tf.nn.selu(tf.matmul(X, enc_W1) + enc_b1)\n",
    "l_encoder2_test = tf.nn.selu(tf.matmul(l_encoder1_test, enc_W2) + enc_b2)\n",
    "\n",
    "# learned representation\n",
    "l_observed_test = tf.matmul(l_encoder2_test, obs_W) + obs_b \n",
    "l_latent_test = tf.matmul(l_encoder2_test, lat_W) + lat_b # linear\n",
    "\n",
    "\n",
    "given_z = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "given_y = tf.placeholder(tf.float32, shape=[None, output_dim])\n",
    "\n",
    "\n",
    "l_representation_test = tf.concat([given_z, given_y], 1)\n",
    "\n",
    "# decoder\n",
    "l_decoder1_test = tf.nn.selu(tf.matmul(l_representation_test, dec_W1) + dec_b1)\n",
    "l_decoder2_test = tf.nn.selu(tf.matmul(l_decoder1_test, dec_W2) + dec_b2)\n",
    "\n",
    "# reconstruction layer\n",
    "l_decoder_out_test = tf.matmul(l_decoder2_test, out_W) + out_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vals = np.empty((0,2), float)\n",
    "# Loop over all batches\n",
    "for i in range(total_batch):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)    \n",
    "    batch_z = sess.run(l_latent_test, feed_dict={X: batch_x}) # TODO usar testing model\n",
    "    z_vals = np.append(z_vals, batch_z, axis=0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(z_vals[:, 0], z_vals[:, 1], alpha=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [85]: A = sess.run(l_decoder_out_test, feed_dict={given_z:np.array([[1,1]]), given_y:np.array([[0,0,0,0,0,0,0,0,0,1]])})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.repeat(np.arange(10), 9).astype('int32')\n",
    "ys = sess.run(tf.one_hot(ys, output_dim))\n",
    "zs = np.tile(np.linspace(-0.5, 0.5, 9), 10).astype(\"float32\")\n",
    "z1s = np.vstack([zs, np.zeros_like(zs)]).T\n",
    "z2s = np.vstack([np.zeros_like(zs), zs]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions_z1 = sess.run(l_decoder_out_test, feed_dict={given_z:z1s, given_y:ys})\n",
    "reconstructions_z2 = sess.run(l_decoder_out_test, feed_dict={given_z:z2s, given_y:ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = reconstructions_z1.reshape(10, 9, 28, 28).transpose(1, 2, 0, 3).reshape(9 * 28, 10 * 28)\n",
    "plt.imshow(im1, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = reconstructions_z2.reshape(10, 9, 28, 28).transpose(1, 2, 0, 3).reshape(9 * 28, 10 * 28)\n",
    "plt.imshow(im2, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
